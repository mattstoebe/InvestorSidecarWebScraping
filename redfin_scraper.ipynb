{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from redfin_scraping_utils import RentScraper, BuyScraper\n",
    "from geocoding_utils import Geocoder \n",
    "import geopandas as  gpd\n",
    "from rentprediction_utils import RentPredictor as RP1  # Replace with your actual module names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_data_for_write(df):\n",
    "    \"\"\"\n",
    "    Cleans the real estate dataset by:\n",
    "    - Removing duplicate columns\n",
    "    - Converting column names to lowercase\n",
    "    - Ensuring appropriate data types\n",
    "    - Replacing NaN values and 'NaN' strings with None for JSON compatibility\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame ready for writing to Supabase.\n",
    "    \"\"\"\n",
    "    # Print initial number of rows\n",
    "    print(f\"Initial number of rows: {len(df)}\")\n",
    "\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    print(\"Converted all column names to lowercase.\")\n",
    "\n",
    "    # Remove duplicate columns, keeping the first occurrence\n",
    "    duplicate_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "    if duplicate_columns:\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "        print(f\"Removed duplicate columns: {duplicate_columns}\")\n",
    "    else:\n",
    "        print(\"No duplicate columns found.\")\n",
    "\n",
    "    # Define a mapping of columns to their desired data types\n",
    "    # Adjust this mapping based on your data's specifics\n",
    "    dtype_mapping = {\n",
    "        'property_id': 'Int64',\n",
    "        'listing_id': 'Int64',\n",
    "        'mls_id': 'string',\n",
    "        'status': 'string',\n",
    "        'price': 'Int64',\n",
    "        'hoa_fee': 'float64',\n",
    "        'square_feet': 'float64',\n",
    "        'lot_size': 'float64',\n",
    "        'bedrooms': 'Int64',\n",
    "        'bathrooms': 'float64',\n",
    "        'location': 'string',\n",
    "        'stories': 'float64',\n",
    "        'address': 'string',\n",
    "        'city': 'string',\n",
    "        'state': 'string',\n",
    "        'zip_code': 'string',\n",
    "        'year_built': 'Int64',\n",
    "        'url': 'string',\n",
    "        'latitude': 'float64',\n",
    "        'longitude': 'float64',\n",
    "        'description': 'string',\n",
    "        'property_type': 'Int64',\n",
    "        'country_code': 'string',\n",
    "        'cbg_geoid': 'string',\n",
    "        'cbsa_geoid': 'string',\n",
    "        'cbsa_name': 'string',\n",
    "        'state_id': 'Int64',\n",
    "        'state_code': 'string',\n",
    "        'beds_rent_benchmark_5_neighbors': 'float64',\n",
    "        'beds_average_distance_5_neighbors': 'float64',\n",
    "        'beds_rent_benchmark_10_neighbors': 'float64',\n",
    "        'beds_average_distance_10_neighbors': 'float64',\n",
    "        'state_code_average_rent': 'float64',\n",
    "        'cbsa_geoid_average_rent': 'float64',\n",
    "        'predicted_rent': 'float32'\n",
    "    }\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    for col, dtype in dtype_mapping.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if dtype.startswith('Int'):\n",
    "                    # For integer columns with nullable type\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').astype(dtype)\n",
    "                elif dtype in ['float64', 'float32']:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').astype(dtype)\n",
    "                elif dtype in ['category', 'string']:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting '{col}' to {dtype}: {e}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    # Replace all pandas NaN with None\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(0)  # Fill NaN with 0 for numeric columns\n",
    "        elif pd.api.types.is_categorical_dtype(df[col]):\n",
    "            df[col] = df[col].cat.fillna('Unknown')  # Add 'Unknown' as category and fill NaN\n",
    "    \n",
    "    print(\"Replaced all pandas NaN values with 0 or Unkown.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Final check for remaining NaNs\n",
    "    total_nans = df.isna().sum().sum()\n",
    "    if total_nans == 0:\n",
    "        print(\"All NaNs have been successfully replaced with None.\")\n",
    "    else:\n",
    "        print(f\"Warning: There are still {total_nans} NaNs remaining.\")\n",
    "        # Identify columns with NaNs\n",
    "        nan_columns = df.columns[df.isna().any()].tolist()\n",
    "        print(f\"Columns with NaNs: {nan_columns}\")\n",
    "\n",
    "    # Print final number of rows\n",
    "    print(f\"Final number of rows: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model loaded from ..\\Models&Training\\knn_beds_model.pkl.\n",
      "XGBoost model loaded from ..\\Models&Training\\xgboost_rent_prediction_model.pkl.\n",
      "Using provided basic_features.\n",
      "Loading rent benchmarks from C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Redfin Data\\rentals_0926.csv...\n",
      "Initial number of rows: 45209\n",
      "Renamed columns for consistency.\n",
      "Converted 'square_feet' to numeric. NaNs before: 11899, after: 11899\n",
      "Converted 'bathrooms' to numeric. NaNs before: 0, after: 0\n",
      "Converted 'bedrooms' to numeric. NaNs before: 0, after: 0\n",
      "Converted 'latitude' to numeric. NaNs before: 0, after: 0\n",
      "Converted 'longitude' to numeric. NaNs before: 0, after: 0\n",
      "Converted 'rent' to numeric. NaNs before: 81, after: 81\n",
      "Cleaned 'state_code' column: converted to uppercase and stripped whitespace.\n",
      "Cleaned 'cbsa_geoid' column: stripped whitespace.\n",
      "All essential columns are present.\n",
      "Dropped duplicate property IDs. Rows before: 45209, after: 45209\n",
      "Unique property types in the data: [ 6  5 13  4]\n",
      "Applying filters:\n",
      "Number of rows before filtering: 45209\n",
      "Number of rows after filtering: 0\n",
      "No data left after filtering. Returning empty DataFrames.\n",
      "Rent benchmarks loaded from C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Redfin Data\\rentals_0926.csv.\n",
      "RentPredictor initialized successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#parameters\n",
    "states = ['WA', 'ID', 'OR', 'MI', 'IL', 'IA', 'WI', 'MN', 'IN']\n",
    "\n",
    "basic_features = [\"square_feet\", \"bedrooms\", \"bathrooms\"]\n",
    "basic_metadata = ['mls_id', 'status', 'price', 'hoa_fee', 'lot_size', \n",
    "       'location', 'stories', 'address', 'city', 'state', 'zip_code',\n",
    "       'year_built', 'url', 'latitude', 'longitude']\n",
    "\n",
    "max_bedrooms = 6\n",
    "min_bedrooms = 0\n",
    "max_bathrooms = 4\n",
    "min_bathrooms = 0\n",
    "max_sqft = 5000\n",
    "max_rent = 10000\n",
    "\n",
    "rent_predictor = RP1(\n",
    "    knn_model_path=r'..\\Models&Training\\knn_beds_model.pkl',\n",
    "    xgboost_model_path=r'..\\Models&Training\\xgboost_rent_prediction_model.pkl',\n",
    "    rent_benchmarks_path=r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Redfin Data\\rentals_0926.csv\",\n",
    "    n_values=[5, 10],\n",
    "    min_bedrooms=min_bedrooms,\n",
    "    max_bedrooms=max_bedrooms,\n",
    "    max_bathrooms=max_bathrooms,\n",
    "    max_rent=max_rent,\n",
    "    basic_features=['square_feet', 'bathrooms', 'bedrooms', \n",
    "                    'latitude', 'longitude', 'state_code', 'cbsa_geoid'],\n",
    "    verbose=True\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Create Supabase Client\n",
    "url: str = os.getenv(\"SUPABASE_URL\")\n",
    "key: str = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "#Initialize Scraper\n",
    "buy_scraper = BuyScraper()\n",
    "rent_scraper = RentScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 325 Zip Codes in ID\n",
      "Processing 24% done (81/325 zip codes)\n",
      "Processing 49% done (162/325 zip codes)\n",
      "Processing 74% done (243/325 zip codes)\n",
      "Scraped 16406 for-sale listings for state ID\n",
      "Geocoding ID\n",
      "Predicting Rent in ID\n",
      "An error occurred while processing state ID: 'state_code'\n"
     ]
    }
   ],
   "source": [
    "states = ['ID']\n",
    "for state in states:\n",
    "    try:\n",
    "        # Initialize a new DataFrame for each state\n",
    "        buy_df = pd.DataFrame()\n",
    "\n",
    "        # Scrape for-sale listings and append to buy_df\n",
    "        buy_data = BuyScraper().scrape_state(state)  # Ensure BuyScraper is properly imported and initialized\n",
    "\n",
    "        if not buy_data.empty:\n",
    "            buy_df = pd.concat([buy_df, buy_data], ignore_index=True)\n",
    "\n",
    "        # Replace NaN with None and drop duplicates based on 'property_id'\n",
    "        buy_df = buy_df.replace(np.nan, None)\n",
    "        buy_df = buy_df.drop_duplicates(subset=\"property_id\")\n",
    "\n",
    "        records = buy_df.to_dict(orient='records')\n",
    "\n",
    "        print(f\"Scraped {len(buy_data)} for-sale listings for state {state}\")\n",
    "\n",
    "        # Initialize Geocoder and perform geocoding\n",
    "        geocoder = Geocoder(\n",
    "            buy_df, \n",
    "            latitude_col='latitude', \n",
    "            longitude_col='longitude'\n",
    "        )\n",
    "\n",
    "        print(f\"Geocoding {state}\")\n",
    "        df_geocoded = geocoder.geocode_all(\n",
    "            demographic_areas_path=r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\census_block_group_source_nationwide\\v107\\blkgrp.gdb\",\n",
    "            cbsa_source_path=r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\cbsa_source\\tl_2020_us_cbsa.shp\", \n",
    "            state_source_path=r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\state_source\\States_shapefile.shp\"\n",
    "        )\n",
    "\n",
    "        print(f\"Predicting Rent in {state}\")\n",
    "        # Process the geocoded data to predict rent\n",
    "        df_predicted = rent_predictor.process(df_geocoded, state)\n",
    "\n",
    "        df_clean = clean_data_for_write(df_predicted)\n",
    "\n",
    "        print(f\"Writing {state}\")\n",
    "\n",
    "        response = (\n",
    "            supabase.table(\"redfin_listings_bronze\")\n",
    "            .upsert(df_clean.to_dict(orient=\"records\"), on_conflict=\"property_id\")\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        print(f\"Write Complete for state {state}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing state {state}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Rent in ID\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'state_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting Rent in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Process the geocoded data to predict rent\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df_predicted \u001b[38;5;241m=\u001b[39m rent_predictor\u001b[38;5;241m.\u001b[39mprocess(df_geocoded, state)\n\u001b[0;32m      5\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m clean_data_for_write(df_predicted)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\OneDrive\\Desktop\\Projects\\stoebebirch\\redfin_scraping_and_geocoding\\rentprediction_utils.py:477\u001b[0m, in \u001b[0;36mRentPredictor.process\u001b[1;34m(self, df_geocoded, state)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in training data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Debugging: Print unique states in training data\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m unique_training_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_avg_rent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique state_code in training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, unique_training_states)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state_code'"
     ]
    }
   ],
   "source": [
    "print(f\"Predicting Rent in {state}\")\n",
    "# Process the geocoded data to predict rent\n",
    "df_predicted = rent_predictor.process(df_geocoded, state)\n",
    "\n",
    "df_clean = clean_data_for_write(df_predicted)\n",
    "\n",
    "print(f\"Writing {state}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rent'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m df_rent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmattl\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreibrowser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDatabase\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRedfin Data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrentals_0926.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m property_types_to_include \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Modify based on actual data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbedrooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m min_bedrooms) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      6\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbedrooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m max_bedrooms) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      7\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbathrooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m max_bathrooms) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      8\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      9\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperty_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(property_types_to_include)) \u001b[38;5;241m&\u001b[39m  \u001b[38;5;66;03m# Adjusted property types\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     (df_rent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_rent)\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows before filtering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_rent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_rent[filters]\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rent'"
     ]
    }
   ],
   "source": [
    "df_rent = pd.read_csv(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Redfin Data\\rentals_0926.csv\")\n",
    "\n",
    "property_types_to_include = [\"6\"]  # Modify based on actual data\n",
    "filters = (\n",
    "    (df_rent[\"bedrooms\"] > min_bedrooms) &\n",
    "    (df_rent[\"bedrooms\"] < max_bedrooms) &\n",
    "    (df_rent[\"bathrooms\"] < max_bathrooms) &\n",
    "    (df_rent[\"state_code\"].notna()) &\n",
    "    (df_rent[\"property_type\"].isin(property_types_to_include)) &  # Adjusted property types\n",
    "    (df_rent[\"rent\"] <= max_rent)\n",
    ")\n",
    "\n",
    "print(f\"Number of rows before filtering: {len(df_rent)}\")\n",
    "df_filtered = df_rent[filters]\n",
    "\n",
    "print(f\"Number of rows after filtering: {len(df_filtered)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
